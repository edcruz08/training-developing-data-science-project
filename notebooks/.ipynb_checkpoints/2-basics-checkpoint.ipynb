{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean and Standard Deviation\n",
    "\n",
    "Welcome! This workshop is from [TrainingDataScience.com](https://trainingdatascience.com/?utm_source=trainingdatascience&utm_medium=notebook&utm_campaign=workshop&utm_term=individual). Sign up to receive more free workshops, training and videos.\n",
    "\n",
    "This workshop is about two fundamental measures of data. I want to you start thinking about how you can best describe or summarise data. How can we best take a set of data and describe that data in as few variables as possible? These are called _summary statistics_ because they summarise statistical data. In other words, this is your first model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean\n",
    "\n",
    "The _mean_, also known as the average, is a measure of the tendency of the data. For example, if you were provided some data then you could say that, on average, is most likely best represented by the mean.\n",
    "\n",
    "The mean is calculated as:\n",
    "\n",
    "$$\\mu = \\frac{\\sum_{i=0}^{N-1}{ x_i }} {N}$$\n",
    "\n",
    "The sum of all observations divided by the number of observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [6, 4, 6, 9, 4, 4, 9, 7, 3, 6];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μ = 5.8\n"
     ]
    }
   ],
   "source": [
    "N = len(x)\n",
    "x_sum = 0\n",
    "for i in range(N):\n",
    "    x_sum = x_sum + x[i]\n",
    "mu = x_sum / N\n",
    "print(\"μ =\", mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we should be using libraries to reduce the amount of code we have to write. For low level tasks such as this, the most common library is called Numpy.\n",
    "\n",
    "We can rewrite the above as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μ = 5.8\n"
     ]
    }
   ],
   "source": [
    "N = len(x)\n",
    "x_sum = np.sum(x)\n",
    "mu = x_sum / N\n",
    "print(\"μ =\", mu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take this even further and just use Numpy's implementation of the mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μ = 5.8\n"
     ]
    }
   ],
   "source": [
    "print(\"μ =\", np.mean(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deviation\n",
    "\n",
    "To describe our data, the mean alone doesn't provide enough information. It tells us what value we should observe on average. But the values could be +/- 1 or +/- 100 of that value. (+/- is shorthand for \"plus or minus\", i.e. \"could be greater than or less than this value\").\n",
    "\n",
    "To provide this information we need a measure of \"spread\" around the mean. The most common measure of \"spread\" is the _standard deviation_.\n",
    "\n",
    "Read more about the standard deviation at: [TrainingDataScience.com - Why do we use Standard Deviation and is it Right?](https://trainingdatascience.com/tips/why-do-we-use-standard-deviation/?utm_source=trainingdatascience&utm_medium=notebook&utm_campaign=workshop&utm_term=individual).\n",
    "\n",
    "The standard deviation of a population is:\n",
    "\n",
    "$$\\sigma = \\sqrt{ \\frac{\\sum_{i=0}^{N-1}{ (x_i - \\mu )^2 }} {N} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [6, 4, 6, 9, 4, 4, 9, 7, 3, 6];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "μ = 5.8\n"
     ]
    }
   ],
   "source": [
    "N = len(x)\n",
    "mu = np.mean(x)\n",
    "print(\"μ =\", mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deviations from the mean: [ 0.2 -1.8  0.2  3.2 -1.8 -1.8  3.2  1.2 -2.8  0.2]\n",
      "Squared deviations from the mean: [  0.04   3.24   0.04  10.24   3.24   3.24  10.24   1.44   7.84   0.04]\n",
      "Sum of squared deviations from the mean: 39.6\n",
      "Mean of squared deviations from the mean: 3.96\n"
     ]
    }
   ],
   "source": [
    "print(\"Deviations from the mean:\", x - mu)\n",
    "print(\"Squared deviations from the mean:\", (x - mu)**2)\n",
    "print(\"Sum of squared deviations from the mean:\", ((x - mu)**2).sum() )\n",
    "print(\"Mean of squared deviations from the mean:\", ((x - mu)**2).sum() / N )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "σ = 1.98997487421\n"
     ]
    }
   ],
   "source": [
    "print(\"σ =\", np.sqrt(((x - mu)**2).sum() / N ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we don't need to code this all up. The Numpy equivalent is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "σ = 1.98997487421\n"
     ]
    }
   ],
   "source": [
    "print(\"σ =\", np.std(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's the Catch?\n",
    "\n",
    "You knew they'd be a catch, right? ;-)\n",
    "\n",
    "I didn't mention it at the start, but the two previous measures of the central tendency and the spread are specific to a very special combination of data.\n",
    "\n",
    "If the observations are _distributed_ in a special way, then these metrics perfectly _model_ the underlying data. If not, then these metrics are invalid.\n",
    "\n",
    "You probably said \"huh?\" to a few of those new words, so let's go through them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Information and Entropy\n",
    "\n",
    "Welcome! This workshop is from [TrainingDataScience.com](https://trainingdatascience.com/?utm_source=trainingdatascience&utm_medium=notebook&utm_campaign=workshop&utm_term=individual). Sign up to receive more free workshops, training and videos.\n",
    "\n",
    "Remember the goal of data science. The goal is to make a decision based upon some data. The quality of that decision depends on our information. If we have good, clear information then we can make well informed decisions. If we have bad, messy data then our decisions will be poor.\n",
    "\n",
    "## Classification\n",
    "\n",
    "In the context of classification, which is the the attempt to predict which _class_ an observation belongs to, we can be more certain about a result if our algorithm is able to separate the classes _cleanly_.\n",
    "\n",
    "One measure of how _clean_ or _pure_ a collection of classes are is Entropy.\n",
    "\n",
    "In this workshop we will mathematically define entropy, which is a measure of the amount of information that can be stored in a limited number of bits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # Numpy is a general purpose mathematical library for Python. \n",
    "                   # Most higher level data science libraries use Numpy under the bonnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.2857142857\n",
      "1225.06122449\n"
     ]
    }
   ],
   "source": [
    "X = np.array([0, 0, 1, 1, -1, -1, 100]) # Create an array. All numpy funcitons expect the data in a Numpy array.\n",
    "print(np.mean(X))\n",
    "print(np.var(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entropy\n",
    "\n",
    "Remember entrpopy is defined as:\n",
    "\n",
    "$$H=-\\sum(p_i \\log_2 (p_i))$$\n",
    "\n",
    "Where \\\\(p_i\\\\) is the probability that the observation belongs to class \\\\(i\\\\). (i.e. $p(y==c)/n$, where y is the target, c is the class of interest and n is the total number of samples)\n",
    "\n",
    "For example, if we have two classes:\n",
    "\n",
    "$$H=-p_1 \\log_2 (p_1)-p_2 \\log_2 (p_2)$$\n",
    "\n",
    "\n",
    "### Task\n",
    "\n",
    "- Read through this code and understand what is going on.\n",
    "- Try calculating the entropy of another array of values. What happens when you add more values? Change values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([0, 0, 1, 1])                                  # They implement all kinds of useful operators, like the == operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(y):\n",
    "    probs = []            # A placeholder for probabilities of each class label\n",
    "    classes = set(y)      # List of classes. A mathematical set. E.g. set([0,0,1,1]) == [0,1]\n",
    "    num_states = len(y)   # Total possible number of states\n",
    "    for c in classes:     # For each class\n",
    "        same_class = y == c               # Which observations have the same class?\n",
    "        num_same_class = sum(same_class)  # Implicit conversion here. sum([true, true, false, false]) == 2\n",
    "        p = num_same_class / num_states   # Probability of this class label (interested states / all possible states)\n",
    "        probs.append(p)\n",
    "    # Now we have the probabilities for all the classes, calculate the entropy\n",
    "    return np.sum(-p * np.log2(p) for p in probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(entropy(y)) # Should be 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information gain\n",
    "\n",
    "Imagine we had some data like that of `X` and `y` above, where `X` are the fetures and `y` are the class labels.\n",
    "\n",
    "We could propose a threshold or a rule that would split the data in `X` to separate the classes. How would we quantify which was the best split?\n",
    "\n",
    "What we can do is compare the entropy of the parent before the split against the weighted combination of the entropy after the split. I.e. if three observations end up in the left bucket and one in the right, then the left bucket will account for three quarters of the child's entropy.\n",
    "\n",
    "If we subtract the parent entropy from the weighted child's entroy, we're left with a measure of _improvement_. This is called the _information gain_.\n",
    "\n",
    "The information gain is defined as the parent entropy minus the weighted entropy of the subgroups.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "IG(parent, children) = & entropy(parent) - \\nonumber \\\\\\\\\n",
    "& \\left(p(c_1)entropy(c_1) + p(c_2)entropy(c_2) + ...\\right)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Tasks:\n",
    "\n",
    "- Given the following `information_gain` function (understand it) pick some splits and calculate the information gain. Which is better?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array([[4.2, 92], [6.4, 102], [3.5, 3], [4.7, 10]])\n",
    "y = np.array([0, 0, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(parent, left_split, right_split):\n",
    "    return entropy(parent) - (len(left_split) / len(parent)) * entropy(left_split) - (len(right_split) / len(parent)) * entropy(right_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31\n"
     ]
    }
   ],
   "source": [
    "# Make a split around the first column, < 5.0:\n",
    "split1 = information_gain(y, y[X[:, 0] < 5.0], y[X[:, 0] > 5.0])\n",
    "print(\"%0.2f\" % split1)   # Should be 0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Split 2 is better\n"
     ]
    }
   ],
   "source": [
    "# Make a split around the second column, < 50.0:\n",
    "split2 = information_gain(y, y[X[:, 1] < 50], y[X[:, 1] > 50])\n",
    "print(split2)   # Should be 1.0\n",
    "print(\"Split %d is better\" % ((split1 < split2) + 1))     # Split 2 should be better, higher information gain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection by information gain\n",
    "\n",
    "Welcome! This workshop is from [TrainingDataScience.com](https://trainingdatascience.com/?utm_source=trainingdatascience&utm_medium=notebook&utm_campaign=workshop&utm_term=individual). Sign up to receive more free workshops, training and videos.\n",
    "\n",
    "One simple way to evaluate the importance of features (something we will deal with later) is to calculate the entropy for prospective splits.\n",
    "\n",
    "In this example, we will look at a real dataset called the [\"mushroom dataset\"](https://archive.ics.uci.edu/ml/datasets/mushroom). It is a large collection of data about poisonous and edible mushrooms.\n",
    "\n",
    "Attribute Information: (classes: edible=e, poisonous=p)\n",
    "     1. cap-shape:                bell=b,conical=c,convex=x,flat=f,\n",
    "                                  knobbed=k,sunken=s\n",
    "     2. cap-surface:              fibrous=f,grooves=g,scaly=y,smooth=s\n",
    "     3. cap-color:                brown=n,buff=b,cinnamon=c,gray=g,green=r,\n",
    "                                  pink=p,purple=u,red=e,white=w,yellow=y\n",
    "     4. bruises?:                 bruises=t,no=f\n",
    "     5. odor:                     almond=a,anise=l,creosote=c,fishy=y,foul=f,\n",
    "                                  musty=m,none=n,pungent=p,spicy=s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises?</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>stalk-shape</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>l</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>u</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>t</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>y</td>\n",
       "      <td>t</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>e</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>k</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  cap-shape cap-surface cap-color bruises? odor gill-attachment gill-spacing  \\\n",
       "0         x           s         y        t    a               f            c   \n",
       "1         b           s         w        t    l               f            c   \n",
       "2         x           y         w        t    p               f            c   \n",
       "3         x           s         g        f    n               f            w   \n",
       "4         x           y         y        t    a               f            c   \n",
       "\n",
       "  gill-size gill-color stalk-shape   ...   stalk-surface-below-ring  \\\n",
       "0         b          k           e   ...                          s   \n",
       "1         b          n           e   ...                          s   \n",
       "2         n          n           e   ...                          s   \n",
       "3         b          k           t   ...                          s   \n",
       "4         b          n           e   ...                          s   \n",
       "\n",
       "  stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "0                      w                      w         p          w   \n",
       "1                      w                      w         p          w   \n",
       "2                      w                      w         p          w   \n",
       "3                      w                      w         p          w   \n",
       "4                      w                      w         p          w   \n",
       "\n",
       "  ring-number ring-type spore-print-color population habitat  \n",
       "0           o         p                 n          n       g  \n",
       "1           o         p                 n          n       m  \n",
       "2           o         p                 k          s       u  \n",
       "3           o         e                 n          a       g  \n",
       "4           o         p                 k          n       g  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    0\n",
       "2    1\n",
       "3    0\n",
       "4    0\n",
       "Name: poisonous, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data with a library called pandas. Pandas is very cool, and we will be using it a lot.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# We're going to use the display module to embed some outputs\n",
    "from IPython.display import display\n",
    "\n",
    "# Read data using Pandas from the UCI data repository.\n",
    "feature_names = [\"poisonous\", \"cap-shape\", \"cap-surface\", \"cap-color\", \"bruises?\", \"odor\", \"gill-attachment\", \"gill-spacing\", \"gill-size\", \"gill-color\", \"stalk-shape\", \"stalk-root\", \"stalk-surface-above-ring\", \"stalk-surface-below-ring\", \"stalk-color-above-ring\", \"stalk-color-below-ring\", \"veil-type\", \"veil-color\", \"ring-number\", \"ring-type\", \"spore-print-color\", \"population\", \"habitat\"]\n",
    "X = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/agaricus-lepiota.data\", header=0, names=feature_names)\n",
    "y = X[\"poisonous\"]                      # Select target label\n",
    "X.drop(['poisonous'], axis=1, inplace=True)   # Remove target label from dataset\n",
    "display(X.head())                       # Show some data\n",
    "\n",
    "y = y.map({\"e\": 0, \"p\": 1})             # Mapping the classes to zeros and ones, not strictly necessary.\n",
    "display(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entire set entropy = 1.00\n"
     ]
    }
   ],
   "source": [
    "# This is the entropy method we defined in the Entropy workshop\n",
    "def entropy(y):\n",
    "    probs = [] # Probabilities of each class label\n",
    "    for c in set(y): # Set gets a unique set of values. We're iterating over each value\n",
    "        num_same_class = sum(y == c)  # Remember that true == 1, so we can sum.\n",
    "        p = num_same_class / len(y) # Probability of this class label\n",
    "        probs.append(p)\n",
    "    return np.sum(-p * np.log2(p) for p in probs)\n",
    "\n",
    "# What is the entropy of the entire set?\n",
    "print(\"Entire set entropy = %.2f\" % entropy(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's write some functions that calculates the entropy after splitting on a particular value\n",
    "\n",
    "def class_probability(feature, y):\n",
    "    \"\"\"Calculates the proportional length of each value in the set of instances\"\"\"\n",
    "    # This is doc string, used for documentation\n",
    "    probs = []\n",
    "    for value in set(feature):\n",
    "        select = feature == value # Split by feature value into two classes\n",
    "        y_new = y[select]         # Those that exist in this class are now in y_new\n",
    "        probs.append(float(len(y_new))/len(X))  # Convert to float, because ints don't divide well\n",
    "    return probs\n",
    "\n",
    "def class_entropy(feature, y):\n",
    "    \"\"\"Calculates the entropy for each value in the set of instances\"\"\"\n",
    "    ents = []\n",
    "    for value in set(feature):\n",
    "        select = feature == value # Split by feature value into two classes\n",
    "        y_new = y[select]         # Those that exist in this class are now in y_new\n",
    "        ents.append(entropy(y_new))\n",
    "    return ents\n",
    "\n",
    "def proportionate_class_entropy(feature, y):\n",
    "    \"\"\"Calculatates the weighted proportional entropy for a feature when splitting on all values\"\"\"\n",
    "    probs = class_probability(feature, y)\n",
    "    ents = class_entropy(feature, y)\n",
    "    return np.sum(np.multiply(probs, ents)) # Information gain equation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain of 0.05\n"
     ]
    }
   ],
   "source": [
    "# Let's try calculating the entropy after splitting by all the values in \"cap-shape\"\n",
    "new_entropy = proportionate_class_entropy(X[\"cap-shape\"], y)\n",
    "print(\"Information gain of %.2f\" % (entropy(y) - new_entropy))\n",
    "# Should be an information gain of 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information gain of 0.91\n"
     ]
    }
   ],
   "source": [
    "# Now let's try doing the same when splitting based upon all values of \"odor\"\n",
    "new_entropy = proportionate_class_entropy(X[\"odor\"], y)\n",
    "print(\"Information gain of %.2f\" % (entropy(y) - new_entropy))\n",
    "# Should be an information gain of 0.91"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, if we were thinking about looking at individual features, then `odor` would be a far better prospect than `cap-shape`.\n",
    "\n",
    "This is cool. You have manually implemented a Decision Tree! Well done! Later on we'll use a library to do this sort of thing.\n",
    "\n",
    "### Which Feature Produces the Best Split?\n",
    "\n",
    "We can repeat this process for all features. The best split is the one with the highest information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cap-shape 0.05\n",
      "cap-surface 0.03\n",
      "cap-color 0.04\n",
      "bruises? 0.19\n",
      "odor 0.91\n",
      "gill-attachment 0.01\n",
      "gill-spacing 0.10\n",
      "gill-size 0.23\n",
      "gill-color 0.42\n",
      "stalk-shape 0.01\n",
      "stalk-root 0.13\n",
      "stalk-surface-above-ring 0.28\n",
      "stalk-surface-below-ring 0.27\n",
      "stalk-color-above-ring 0.25\n",
      "stalk-color-below-ring 0.24\n",
      "veil-type 0.00\n",
      "veil-color 0.02\n",
      "ring-number 0.04\n",
      "ring-type 0.32\n",
      "spore-print-color 0.48\n",
      "population 0.20\n",
      "habitat 0.16\n"
     ]
    }
   ],
   "source": [
    "for c in X.columns:\n",
    "    new_entropy = proportionate_class_entropy(X[c], y)\n",
    "    print(\"%s %.2f\" % (c, entropy(y) - new_entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting\n",
    "\n",
    "Throughout data science, results are more intruitive to reason about if you present the data or the results in different media.\n",
    "\n",
    "Plotting is used for everything; investigating data through to presenting results.\n",
    "\n",
    "You should become familiar with plotting data; below we go through a fairly comprehensive example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matplotlib is _the_ plotting library for python. Most other tools are based \n",
    "# upon matplot lib. We will use others as appropriate in the future (mainly\n",
    "# pandas's helpers)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "colours = 'bgrcmk'  # An array of colours used during plotting later on.\n",
    "\n",
    "def plot_entropy(probability, entropy, labels):\n",
    "    \"\"\"Graphical representation of entropy when splitting on each value\"\"\"\n",
    "\n",
    "    # Some complex calculations to get the centre of the bars\n",
    "    positions = np.array([0])\n",
    "    positions = np.concatenate((positions, np.cumsum(probability)[:-1]))\n",
    "    positions += np.divide(probability, 2)\n",
    "    \n",
    "    # Plot bars with colours\n",
    "    plt.bar(positions, entropy, width=probability, color=colours[:len(probability)])\n",
    "\n",
    "    # Set limits\n",
    "    plt.ylim([0, 1])\n",
    "    plt.xlim([0, 1])\n",
    "    \n",
    "    # Labels\n",
    "    plt.ylabel(\"Entropy\")\n",
    "    plt.xlabel(\"Probability\")\n",
    "    \n",
    "    # If labels are provided, plot some text\n",
    "    if labels:\n",
    "        props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)\n",
    "        for i, lab in enumerate(labels):\n",
    "            # Plot text\n",
    "            plt.text(positions[i], 0.1, lab, fontsize=14, verticalalignment='top', bbox=props)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe77cc63550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for \"cap-shape\" feature\n",
    "feature = X[\"cap-shape\"]\n",
    "# Calculate probabilities and entropies\n",
    "probs = class_probability(feature, y)\n",
    "ents = class_entropy(feature, y)\n",
    "labels = set(feature)\n",
    "plot_entropy(probs, ents, labels)\n",
    "plt.show() # You must run `plt.show()` at the end to show your plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are plotting the entropy on the y-axis and the proportion of the dataset included when performing that split on the x-axis.\n",
    "\n",
    "This plot works well for categorical features.\n",
    "\n",
    "The total entropy of this split is the area that is covered by all of the bars.\n",
    "\n",
    "We can see that there isn't much whitespace; i.e. not much information gain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe7a702f128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot for \"odor\" feature\n",
    "feature = X[\"odor\"]\n",
    "probs = class_probability(feature, y)\n",
    "ents = class_entropy(feature, y)\n",
    "labels = set(feature)\n",
    "plot_entropy(probs, ents, labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time there is lots of whitespace. The total area is very small.\n",
    "\n",
    "The propotionate entropy is visibly smaller.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "- Which is the better feature to use, `gill-size` or `veil-color`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Decision Trees in SKLearn\n",
    "\n",
    "Surprisingly, there are still no categorical decision tree implementations in sklearn. You can read more about one proposal [here](https://github.com/scikit-learn/scikit-learn/pull/4899).\n",
    "\n",
    "So instead, if you wanted to use sklearn, you would have to one-hot encode the categories (which we haven't learnt yet)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
